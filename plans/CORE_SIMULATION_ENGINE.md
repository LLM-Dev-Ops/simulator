# Core Simulation Engine - Production-Ready Pseudocode

**Module**: `simulation_engine`
**Purpose**: Enterprise-grade orchestration of LLM simulation requests with deterministic execution, high throughput, and comprehensive observability.

**Performance Requirements**:
- 10,000+ requests/second throughput
- <5ms processing overhead per request
- Deterministic execution with seed-based reproducibility
- Graceful degradation under load

---

## Table of Contents
1. [Core Traits and Type Definitions](#core-traits-and-type-definitions)
2. [Simulation Engine Architecture](#simulation-engine-architecture)
3. [Request Processing Pipeline](#request-processing-pipeline)
4. [Deterministic RNG System](#deterministic-rng-system)
5. [Session and State Management](#session-and-state-management)
6. [Queue and Backpressure](#queue-and-backpressure)
7. [Shutdown and Resource Cleanup](#shutdown-and-resource-cleanup)
8. [Error Handling](#error-handling)
9. [Observability Integration](#observability-integration)

---

## Core Traits and Type Definitions

```rust
// ============================================================================
// MODULE: simulation_engine::types
// PURPOSE: Core type definitions and error types
// ============================================================================

use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{RwLock, Semaphore, mpsc, oneshot};
use thiserror::Error;
use serde::{Serialize, Deserialize};

/// Request identifier for tracking and correlation
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct RequestId(u64);

/// Session identifier for conversation grouping
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct SessionId(String);

/// Conversation identifier within a session
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct ConversationId(u64);

/// Unified error type for simulation engine operations
#[derive(Error, Debug)]
pub enum SimulationError {
    #[error("Engine not initialized")]
    NotInitialized,

    #[error("Engine already running")]
    AlreadyRunning,

    #[error("Engine is shutting down")]
    ShuttingDown,

    #[error("Request queue full: capacity={capacity}, current={current}")]
    QueueFull { capacity: usize, current: usize },

    #[error("Request timeout after {0:?}")]
    RequestTimeout(Duration),

    #[error("Session not found: {0}")]
    SessionNotFound(SessionId),

    #[error("Invalid request: {0}")]
    InvalidRequest(String),

    #[error("Provider error: {0}")]
    ProviderError(String),

    #[error("State corruption detected: {0}")]
    StateCorruption(String),

    #[error("Resource exhaustion: {0}")]
    ResourceExhaustion(String),

    #[error("Determinism violation: {0}")]
    DeterminismViolation(String),

    #[error("Internal error: {0}")]
    Internal(String),
}

/// Result type for simulation operations
pub type SimResult<T> = Result<T, SimulationError>;

/// Provider-agnostic request structure
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SimulationRequest {
    /// Unique request identifier
    pub id: RequestId,

    /// Session this request belongs to
    pub session_id: SessionId,

    /// Conversation within the session
    pub conversation_id: Option<ConversationId>,

    /// Target provider (e.g., "openai", "anthropic", "gemini")
    pub provider: String,

    /// Model identifier
    pub model: String,

    /// Request payload (provider-specific format)
    pub payload: serde_json::Value,

    /// Request metadata
    pub metadata: RequestMetadata,

    /// When this request was created
    pub created_at: Instant,
}

/// Metadata associated with a request
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RequestMetadata {
    /// Client-provided correlation ID
    pub correlation_id: Option<String>,

    /// Request priority (0-255, higher is more important)
    pub priority: u8,

    /// Maximum time to wait for response
    pub timeout: Duration,

    /// RNG seed for deterministic behavior
    pub seed: Option<u64>,

    /// Custom tags for filtering/routing
    pub tags: Vec<String>,
}

/// Response from simulation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SimulationResponse {
    /// Request ID this responds to
    pub request_id: RequestId,

    /// Response payload (provider-specific format)
    pub payload: serde_json::Value,

    /// Performance metrics
    pub metrics: ResponseMetrics,

    /// When response was generated
    pub completed_at: Instant,
}

/// Performance metrics for observability
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResponseMetrics {
    /// Time spent in queue
    pub queue_time_ms: f64,

    /// Time spent processing
    pub processing_time_ms: f64,

    /// Total time from submission to completion
    pub total_time_ms: f64,

    /// RNG operations performed
    pub rng_operations: u32,

    /// State lookups performed
    pub state_lookups: u32,

    /// Tokens generated (if applicable)
    pub tokens_generated: Option<u32>,
}

/// Engine configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EngineConfig {
    /// Maximum concurrent requests
    pub max_concurrent_requests: usize,

    /// Request queue capacity
    pub queue_capacity: usize,

    /// Worker thread pool size
    pub worker_threads: usize,

    /// Global RNG seed (if deterministic mode)
    pub global_seed: Option<u64>,

    /// Session state retention period
    pub session_ttl: Duration,

    /// Conversation history limit
    pub max_conversation_history: usize,

    /// Request timeout default
    pub default_timeout: Duration,

    /// Enable detailed metrics
    pub enable_metrics: bool,

    /// Enable request tracing
    pub enable_tracing: bool,

    /// Backpressure threshold (0.0-1.0)
    pub backpressure_threshold: f64,

    /// Graceful shutdown timeout
    pub shutdown_timeout: Duration,
}

impl Default for EngineConfig {
    fn default() -> Self {
        Self {
            max_concurrent_requests: 1000,
            queue_capacity: 10000,
            worker_threads: num_cpus::get(),
            global_seed: None,
            session_ttl: Duration::from_secs(3600),
            max_conversation_history: 100,
            default_timeout: Duration::from_secs(30),
            enable_metrics: true,
            enable_tracing: true,
            backpressure_threshold: 0.8,
            shutdown_timeout: Duration::from_secs(30),
        }
    }
}

/// Engine state
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum EngineState {
    /// Engine not yet initialized
    Uninitialized,

    /// Engine initialized but not started
    Initialized,

    /// Engine running and accepting requests
    Running,

    /// Engine in graceful shutdown
    ShuttingDown,

    /// Engine stopped
    Stopped,
}

// ============================================================================
// MODULE: simulation_engine::traits
// PURPOSE: Core trait definitions for extensibility
// ============================================================================

/// Trait for provider-specific LLM simulation
#[async_trait::async_trait]
pub trait LLMProvider: Send + Sync {
    /// Provider identifier (e.g., "openai", "anthropic")
    fn provider_name(&self) -> &str;

    /// Supported models for this provider
    fn supported_models(&self) -> Vec<String>;

    /// Process a request and generate response
    async fn process_request(
        &self,
        request: &SimulationRequest,
        rng: &mut dyn DeterministicRng,
        context: &RequestContext,
    ) -> SimResult<SimulationResponse>;

    /// Validate request format before processing
    fn validate_request(&self, request: &SimulationRequest) -> SimResult<()>;

    /// Estimate processing time for load balancing
    fn estimate_processing_time(&self, request: &SimulationRequest) -> Duration;
}

/// Trait for deterministic random number generation
pub trait DeterministicRng: Send {
    /// Generate random u64
    fn next_u64(&mut self) -> u64;

    /// Generate random f64 in [0, 1)
    fn next_f64(&mut self) -> f64;

    /// Generate random number in range [min, max)
    fn gen_range(&mut self, min: u64, max: u64) -> u64;

    /// Fill buffer with random bytes
    fn fill_bytes(&mut self, dest: &mut [u8]);

    /// Get current RNG state for checkpointing
    fn get_state(&self) -> Vec<u8>;

    /// Restore RNG state from checkpoint
    fn set_state(&mut self, state: &[u8]) -> SimResult<()>;

    /// Create a child RNG with derived seed
    fn fork(&mut self) -> Box<dyn DeterministicRng>;
}

/// Trait for session state storage
#[async_trait::async_trait]
pub trait SessionStore: Send + Sync {
    /// Get or create session
    async fn get_or_create_session(
        &self,
        session_id: &SessionId,
    ) -> SimResult<Arc<RwLock<SessionState>>>;

    /// Get existing session
    async fn get_session(
        &self,
        session_id: &SessionId,
    ) -> SimResult<Arc<RwLock<SessionState>>>;

    /// Remove session
    async fn remove_session(&self, session_id: &SessionId) -> SimResult<()>;

    /// List all active sessions
    async fn list_sessions(&self) -> SimResult<Vec<SessionId>>;

    /// Cleanup expired sessions
    async fn cleanup_expired(&self, ttl: Duration) -> SimResult<usize>;
}

/// Trait for metrics collection
pub trait MetricsCollector: Send + Sync {
    /// Record request received
    fn record_request_received(&self, request: &SimulationRequest);

    /// Record request completed
    fn record_request_completed(&self, response: &SimulationResponse);

    /// Record request failed
    fn record_request_failed(&self, request_id: RequestId, error: &SimulationError);

    /// Record queue depth
    fn record_queue_depth(&self, depth: usize);

    /// Record active requests
    fn record_active_requests(&self, count: usize);

    /// Record backpressure event
    fn record_backpressure(&self);

    /// Get current metrics snapshot
    fn snapshot(&self) -> MetricsSnapshot;
}

/// Snapshot of current metrics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MetricsSnapshot {
    pub total_requests: u64,
    pub successful_requests: u64,
    pub failed_requests: u64,
    pub current_queue_depth: usize,
    pub active_requests: usize,
    pub avg_processing_time_ms: f64,
    pub p50_processing_time_ms: f64,
    pub p95_processing_time_ms: f64,
    pub p99_processing_time_ms: f64,
    pub backpressure_events: u64,
    pub timestamp: Instant,
}

/// Context provided during request processing
#[derive(Debug)]
pub struct RequestContext {
    /// Session state
    pub session: Arc<RwLock<SessionState>>,

    /// Conversation state (if applicable)
    pub conversation: Option<Arc<RwLock<ConversationState>>>,

    /// Metrics collector
    pub metrics: Arc<dyn MetricsCollector>,

    /// Trace span (for distributed tracing)
    pub trace_id: Option<String>,

    /// Processing start time
    pub started_at: Instant,
}
```

---

## Simulation Engine Architecture

```rust
// ============================================================================
// MODULE: simulation_engine::engine
// PURPOSE: Main simulation engine orchestration
// ============================================================================

use std::collections::HashMap;
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};

/// Core simulation engine
///
/// Thread-safe, async-first design supporting high-concurrency workloads.
/// All state is protected by appropriate synchronization primitives.
pub struct SimulationEngine {
    /// Engine configuration
    config: EngineConfig,

    /// Current engine state
    state: Arc<RwLock<EngineState>>,

    /// Registered LLM providers
    providers: Arc<RwLock<HashMap<String, Arc<dyn LLMProvider>>>>,

    /// Session state store
    session_store: Arc<dyn SessionStore>,

    /// Request queue for backpressure management
    request_queue: Arc<RequestQueue>,

    /// Semaphore for concurrency control
    concurrency_limiter: Arc<Semaphore>,

    /// Global deterministic RNG (if configured)
    global_rng: Arc<RwLock<Option<Box<dyn DeterministicRng>>>>,

    /// Metrics collector
    metrics: Arc<dyn MetricsCollector>,

    /// Shutdown signal channel
    shutdown_tx: Arc<RwLock<Option<mpsc::Sender<()>>>>,

    /// Request ID generator
    next_request_id: Arc<AtomicU64>,

    /// Active request tracking
    active_requests: Arc<AtomicUsize>,

    /// Background task handles
    task_handles: Arc<RwLock<Vec<tokio::task::JoinHandle<()>>>>,
}

impl SimulationEngine {
    /// Create a new simulation engine with the given configuration
    ///
    /// # Arguments
    /// * `config` - Engine configuration
    ///
    /// # Returns
    /// * `SimResult<Self>` - Initialized engine or error
    ///
    /// # Thread Safety
    /// This method is thread-safe and can be called from multiple threads.
    pub fn new(config: EngineConfig) -> SimResult<Self> {
        // Validate configuration
        Self::validate_config(&config)?;

        // Initialize RNG if deterministic mode
        let global_rng = if let Some(seed) = config.global_seed {
            Some(Box::new(XorShift64Star::new(seed)) as Box<dyn DeterministicRng>)
        } else {
            None
        };

        // Create session store
        let session_store = Arc::new(InMemorySessionStore::new(
            config.session_ttl,
            config.max_conversation_history,
        ));

        // Create request queue
        let request_queue = Arc::new(RequestQueue::new(
            config.queue_capacity,
            config.backpressure_threshold,
        ));

        // Create concurrency limiter
        let concurrency_limiter = Arc::new(Semaphore::new(config.max_concurrent_requests));

        // Create metrics collector
        let metrics = Arc::new(PrometheusMetricsCollector::new());

        Ok(Self {
            config,
            state: Arc::new(RwLock::new(EngineState::Initialized)),
            providers: Arc::new(RwLock::new(HashMap::new())),
            session_store,
            request_queue,
            concurrency_limiter,
            global_rng: Arc::new(RwLock::new(global_rng)),
            metrics,
            shutdown_tx: Arc::new(RwLock::new(None)),
            next_request_id: Arc::new(AtomicU64::new(1)),
            active_requests: Arc::new(AtomicUsize::new(0)),
            task_handles: Arc::new(RwLock::new(Vec::new())),
        })
    }

    /// Validate engine configuration
    fn validate_config(config: &EngineConfig) -> SimResult<()> {
        if config.max_concurrent_requests == 0 {
            return Err(SimulationError::InvalidRequest(
                "max_concurrent_requests must be > 0".to_string()
            ));
        }

        if config.queue_capacity == 0 {
            return Err(SimulationError::InvalidRequest(
                "queue_capacity must be > 0".to_string()
            ));
        }

        if config.worker_threads == 0 {
            return Err(SimulationError::InvalidRequest(
                "worker_threads must be > 0".to_string()
            ));
        }

        if config.backpressure_threshold < 0.0 || config.backpressure_threshold > 1.0 {
            return Err(SimulationError::InvalidRequest(
                "backpressure_threshold must be in [0.0, 1.0]".to_string()
            ));
        }

        Ok(())
    }

    /// Register an LLM provider
    ///
    /// # Arguments
    /// * `provider` - Provider implementation to register
    ///
    /// # Returns
    /// * `SimResult<()>` - Success or error
    ///
    /// # Thread Safety
    /// This method acquires a write lock on the providers map.
    pub async fn register_provider(
        &self,
        provider: Arc<dyn LLMProvider>,
    ) -> SimResult<()> {
        let provider_name = provider.provider_name().to_string();

        let mut providers = self.providers.write().await;

        if providers.contains_key(&provider_name) {
            return Err(SimulationError::InvalidRequest(
                format!("Provider '{}' already registered", provider_name)
            ));
        }

        providers.insert(provider_name.clone(), provider);

        tracing::info!(
            provider = %provider_name,
            "Provider registered successfully"
        );

        Ok(())
    }

    /// Start the simulation engine
    ///
    /// Spawns background worker tasks and begins accepting requests.
    ///
    /// # Returns
    /// * `SimResult<()>` - Success or error
    ///
    /// # Side Effects
    /// - Transitions state from Initialized to Running
    /// - Spawns background worker tasks
    /// - Initializes shutdown channel
    pub async fn start(&self) -> SimResult<()> {
        let mut state = self.state.write().await;

        match *state {
            EngineState::Uninitialized => {
                return Err(SimulationError::NotInitialized);
            }
            EngineState::Running => {
                return Err(SimulationError::AlreadyRunning);
            }
            EngineState::ShuttingDown | EngineState::Stopped => {
                return Err(SimulationError::Internal(
                    "Cannot start engine in current state".to_string()
                ));
            }
            EngineState::Initialized => {}
        }

        // Create shutdown channel
        let (shutdown_tx, shutdown_rx) = mpsc::channel(1);
        *self.shutdown_tx.write().await = Some(shutdown_tx);

        // Spawn worker tasks
        let mut handles = Vec::new();

        for worker_id in 0..self.config.worker_threads {
            let handle = self.spawn_worker(worker_id, shutdown_rx.clone());
            handles.push(handle);
        }

        // Spawn session cleanup task
        let cleanup_handle = self.spawn_session_cleanup_task(shutdown_rx.clone());
        handles.push(cleanup_handle);

        // Spawn metrics reporting task
        if self.config.enable_metrics {
            let metrics_handle = self.spawn_metrics_task(shutdown_rx.clone());
            handles.push(metrics_handle);
        }

        *self.task_handles.write().await = handles;

        // Transition to running state
        *state = EngineState::Running;

        tracing::info!(
            workers = self.config.worker_threads,
            "Simulation engine started successfully"
        );

        Ok(())
    }

    /// Submit a request for processing
    ///
    /// # Arguments
    /// * `request` - Request to process
    ///
    /// # Returns
    /// * `SimResult<SimulationResponse>` - Response or error
    ///
    /// # Behavior
    /// - Validates request
    /// - Checks backpressure
    /// - Enqueues request
    /// - Waits for response or timeout
    pub async fn submit_request(
        &self,
        mut request: SimulationRequest,
    ) -> SimResult<SimulationResponse> {
        // Check engine state
        let state = self.state.read().await;
        match *state {
            EngineState::Running => {}
            EngineState::ShuttingDown => {
                return Err(SimulationError::ShuttingDown);
            }
            _ => {
                return Err(SimulationError::NotInitialized);
            }
        }
        drop(state);

        // Assign request ID if not present
        if request.id.0 == 0 {
            request.id = RequestId(self.next_request_id.fetch_add(1, Ordering::SeqCst));
        }

        // Validate request
        self.validate_request(&request).await?;

        // Record metrics
        self.metrics.record_request_received(&request);

        // Create response channel
        let (response_tx, response_rx) = oneshot::channel();

        // Enqueue request
        let timeout = request.metadata.timeout;
        self.request_queue.enqueue(request, response_tx).await?;

        // Update metrics
        self.metrics.record_queue_depth(self.request_queue.len().await);

        // Wait for response with timeout
        match tokio::time::timeout(timeout, response_rx).await {
            Ok(Ok(response)) => {
                self.metrics.record_request_completed(&response);
                Ok(response)
            }
            Ok(Err(_)) => {
                // Channel closed unexpectedly
                Err(SimulationError::Internal(
                    "Response channel closed".to_string()
                ))
            }
            Err(_) => {
                // Timeout
                Err(SimulationError::RequestTimeout(timeout))
            }
        }
    }

    /// Validate a request before processing
    async fn validate_request(&self, request: &SimulationRequest) -> SimResult<()> {
        // Check provider exists
        let providers = self.providers.read().await;
        let provider = providers.get(&request.provider)
            .ok_or_else(|| SimulationError::InvalidRequest(
                format!("Unknown provider: {}", request.provider)
            ))?;

        // Delegate to provider for validation
        provider.validate_request(request)?;

        Ok(())
    }

    /// Spawn a worker task
    fn spawn_worker(
        &self,
        worker_id: usize,
        mut shutdown_rx: mpsc::Receiver<()>,
    ) -> tokio::task::JoinHandle<()> {
        let queue = Arc::clone(&self.request_queue);
        let providers = Arc::clone(&self.providers);
        let session_store = Arc::clone(&self.session_store);
        let concurrency_limiter = Arc::clone(&self.concurrency_limiter);
        let global_rng = Arc::clone(&self.global_rng);
        let metrics = Arc::clone(&self.metrics);
        let active_requests = Arc::clone(&self.active_requests);
        let config = self.config.clone();

        tokio::spawn(async move {
            tracing::debug!(worker_id, "Worker started");

            loop {
                tokio::select! {
                    // Check for shutdown signal
                    _ = shutdown_rx.recv() => {
                        tracing::debug!(worker_id, "Worker received shutdown signal");
                        break;
                    }

                    // Process next request
                    result = queue.dequeue() => {
                        match result {
                            Ok((request, response_tx)) => {
                                // Acquire concurrency permit
                                let permit = concurrency_limiter.acquire().await.unwrap();

                                active_requests.fetch_add(1, Ordering::SeqCst);
                                metrics.record_active_requests(
                                    active_requests.load(Ordering::SeqCst)
                                );

                                // Process request
                                let response = Self::process_request_internal(
                                    request,
                                    &providers,
                                    &session_store,
                                    &global_rng,
                                    &metrics,
                                    &config,
                                ).await;

                                active_requests.fetch_sub(1, Ordering::SeqCst);
                                metrics.record_active_requests(
                                    active_requests.load(Ordering::SeqCst)
                                );

                                // Release permit
                                drop(permit);

                                // Send response
                                match response {
                                    Ok(resp) => {
                                        let _ = response_tx.send(resp);
                                    }
                                    Err(err) => {
                                        tracing::error!(
                                            worker_id,
                                            error = %err,
                                            "Request processing failed"
                                        );
                                        // Response channel will be dropped, causing timeout
                                    }
                                }
                            }
                            Err(err) => {
                                // Queue error - should rarely happen
                                tracing::error!(
                                    worker_id,
                                    error = %err,
                                    "Failed to dequeue request"
                                );
                                tokio::time::sleep(Duration::from_millis(10)).await;
                            }
                        }
                    }
                }
            }

            tracing::debug!(worker_id, "Worker stopped");
        })
    }

    /// Internal request processing logic
    async fn process_request_internal(
        request: SimulationRequest,
        providers: &Arc<RwLock<HashMap<String, Arc<dyn LLMProvider>>>>,
        session_store: &Arc<dyn SessionStore>,
        global_rng: &Arc<RwLock<Option<Box<dyn DeterministicRng>>>>,
        metrics: &Arc<dyn MetricsCollector>,
        config: &EngineConfig,
    ) -> SimResult<SimulationResponse> {
        let started_at = Instant::now();
        let queue_time_ms = (started_at - request.created_at).as_secs_f64() * 1000.0;

        // Get provider
        let providers_guard = providers.read().await;
        let provider = providers_guard.get(&request.provider)
            .ok_or_else(|| SimulationError::ProviderError(
                format!("Provider '{}' not found", request.provider)
            ))?
            .clone();
        drop(providers_guard);

        // Get or create session
        let session = session_store.get_or_create_session(&request.session_id).await?;

        // Get conversation state if needed
        let conversation = if let Some(conv_id) = request.conversation_id {
            let mut session_guard = session.write().await;
            Some(session_guard.get_or_create_conversation(conv_id))
        } else {
            None
        };

        // Create RNG for this request
        let mut rng = Self::create_request_rng(
            &request,
            global_rng,
            config,
        ).await?;

        // Build request context
        let context = RequestContext {
            session,
            conversation,
            metrics: Arc::clone(metrics),
            trace_id: request.metadata.correlation_id.clone(),
            started_at,
        };

        // Process request through provider
        let mut response = provider.process_request(
            &request,
            &mut *rng,
            &context,
        ).await?;

        // Update metrics
        let processing_time_ms = (Instant::now() - started_at).as_secs_f64() * 1000.0;
        response.metrics.queue_time_ms = queue_time_ms;
        response.metrics.processing_time_ms = processing_time_ms;
        response.metrics.total_time_ms = queue_time_ms + processing_time_ms;

        Ok(response)
    }

    /// Create RNG for a request
    async fn create_request_rng(
        request: &SimulationRequest,
        global_rng: &Arc<RwLock<Option<Box<dyn DeterministicRng>>>>,
        config: &EngineConfig,
    ) -> SimResult<Box<dyn DeterministicRng>> {
        // Use request-specific seed if provided
        if let Some(seed) = request.metadata.seed {
            return Ok(Box::new(XorShift64Star::new(seed)));
        }

        // Use global RNG to derive seed if deterministic mode
        let mut global_guard = global_rng.write().await;
        if let Some(ref mut global) = *global_guard {
            return Ok(global.fork());
        }

        // Non-deterministic mode - use thread RNG
        Ok(Box::new(ThreadRng::new()))
    }

    /// Spawn session cleanup task
    fn spawn_session_cleanup_task(
        &self,
        mut shutdown_rx: mpsc::Receiver<()>,
    ) -> tokio::task::JoinHandle<()> {
        let session_store = Arc::clone(&self.session_store);
        let ttl = self.config.session_ttl;
        let cleanup_interval = Duration::from_secs(60);

        tokio::spawn(async move {
            tracing::debug!("Session cleanup task started");

            let mut interval = tokio::time::interval(cleanup_interval);

            loop {
                tokio::select! {
                    _ = shutdown_rx.recv() => {
                        tracing::debug!("Session cleanup task received shutdown signal");
                        break;
                    }

                    _ = interval.tick() => {
                        match session_store.cleanup_expired(ttl).await {
                            Ok(count) => {
                                if count > 0 {
                                    tracing::debug!(
                                        cleaned = count,
                                        "Cleaned up expired sessions"
                                    );
                                }
                            }
                            Err(err) => {
                                tracing::error!(
                                    error = %err,
                                    "Session cleanup failed"
                                );
                            }
                        }
                    }
                }
            }

            tracing::debug!("Session cleanup task stopped");
        })
    }

    /// Spawn metrics reporting task
    fn spawn_metrics_task(
        &self,
        mut shutdown_rx: mpsc::Receiver<()>,
    ) -> tokio::task::JoinHandle<()> {
        let metrics = Arc::clone(&self.metrics);
        let report_interval = Duration::from_secs(10);

        tokio::spawn(async move {
            tracing::debug!("Metrics reporting task started");

            let mut interval = tokio::time::interval(report_interval);

            loop {
                tokio::select! {
                    _ = shutdown_rx.recv() => {
                        tracing::debug!("Metrics task received shutdown signal");
                        break;
                    }

                    _ = interval.tick() => {
                        let snapshot = metrics.snapshot();

                        tracing::info!(
                            total_requests = snapshot.total_requests,
                            successful = snapshot.successful_requests,
                            failed = snapshot.failed_requests,
                            queue_depth = snapshot.current_queue_depth,
                            active = snapshot.active_requests,
                            avg_processing_ms = snapshot.avg_processing_time_ms,
                            p95_processing_ms = snapshot.p95_processing_time_ms,
                            "Metrics snapshot"
                        );
                    }
                }
            }

            tracing::debug!("Metrics reporting task stopped");
        })
    }

    /// Initiate graceful shutdown
    ///
    /// # Returns
    /// * `SimResult<()>` - Success or error
    ///
    /// # Behavior
    /// - Stops accepting new requests
    /// - Waits for active requests to complete (up to timeout)
    /// - Cleans up resources
    /// - Joins worker tasks
    pub async fn shutdown(&self) -> SimResult<()> {
        let mut state = self.state.write().await;

        match *state {
            EngineState::Running => {}
            EngineState::ShuttingDown | EngineState::Stopped => {
                tracing::warn!("Shutdown already in progress or complete");
                return Ok(());
            }
            _ => {
                return Err(SimulationError::Internal(
                    "Cannot shutdown engine in current state".to_string()
                ));
            }
        }

        *state = EngineState::ShuttingDown;
        drop(state);

        tracing::info!("Initiating graceful shutdown");

        // Send shutdown signal to all workers
        if let Some(tx) = self.shutdown_tx.write().await.take() {
            drop(tx); // Dropping sender closes the channel
        }

        // Wait for active requests to complete (with timeout)
        let shutdown_deadline = Instant::now() + self.config.shutdown_timeout;

        while self.active_requests.load(Ordering::SeqCst) > 0 {
            if Instant::now() > shutdown_deadline {
                tracing::warn!(
                    remaining = self.active_requests.load(Ordering::SeqCst),
                    "Shutdown timeout reached with active requests remaining"
                );
                break;
            }

            tokio::time::sleep(Duration::from_millis(100)).await;
        }

        // Wait for worker tasks to complete
        let mut handles = self.task_handles.write().await;
        for handle in handles.drain(..) {
            if let Err(err) = handle.await {
                tracing::error!(error = ?err, "Worker task join failed");
            }
        }

        // Final metrics snapshot
        let snapshot = self.metrics.snapshot();
        tracing::info!(
            total_requests = snapshot.total_requests,
            successful = snapshot.successful_requests,
            failed = snapshot.failed_requests,
            "Final metrics snapshot"
        );

        // Transition to stopped state
        let mut state = self.state.write().await;
        *state = EngineState::Stopped;

        tracing::info!("Shutdown complete");

        Ok(())
    }

    /// Get current engine state
    pub async fn get_state(&self) -> EngineState {
        *self.state.read().await
    }

    /// Get metrics snapshot
    pub fn get_metrics(&self) -> MetricsSnapshot {
        self.metrics.snapshot()
    }

    /// Get active session count
    pub async fn get_active_session_count(&self) -> SimResult<usize> {
        Ok(self.session_store.list_sessions().await?.len())
    }
}

/// RAII guard for automatic shutdown on drop
pub struct EngineGuard {
    engine: Arc<SimulationEngine>,
}

impl EngineGuard {
    pub fn new(engine: Arc<SimulationEngine>) -> Self {
        Self { engine }
    }
}

impl Drop for EngineGuard {
    fn drop(&mut self) {
        // Spawn shutdown on drop (fire and forget)
        let engine = Arc::clone(&self.engine);
        tokio::spawn(async move {
            if let Err(err) = engine.shutdown().await {
                tracing::error!(error = %err, "Shutdown failed");
            }
        });
    }
}
```

---

## Request Processing Pipeline

```rust
// ============================================================================
// MODULE: simulation_engine::queue
// PURPOSE: Request queue with backpressure management
// ============================================================================

use std::collections::VecDeque;

/// Request queue with backpressure detection
pub struct RequestQueue {
    /// Internal queue storage
    queue: Arc<RwLock<VecDeque<QueuedRequest>>>,

    /// Queue capacity
    capacity: usize,

    /// Backpressure threshold
    backpressure_threshold: f64,

    /// Queue length counter
    len: Arc<AtomicUsize>,

    /// Notification mechanism for dequeue operations
    notify: Arc<tokio::sync::Notify>,
}

/// Request with response channel
struct QueuedRequest {
    request: SimulationRequest,
    response_tx: oneshot::Sender<SimulationResponse>,
    enqueued_at: Instant,
}

impl RequestQueue {
    /// Create a new request queue
    pub fn new(capacity: usize, backpressure_threshold: f64) -> Self {
        Self {
            queue: Arc::new(RwLock::new(VecDeque::with_capacity(capacity))),
            capacity,
            backpressure_threshold,
            len: Arc::new(AtomicUsize::new(0)),
            notify: Arc::new(tokio::sync::Notify::new()),
        }
    }

    /// Enqueue a request
    ///
    /// # Arguments
    /// * `request` - Request to enqueue
    /// * `response_tx` - Channel to send response on
    ///
    /// # Returns
    /// * `SimResult<()>` - Success or queue full error
    ///
    /// # Backpressure
    /// Returns error if queue is at capacity.
    pub async fn enqueue(
        &self,
        request: SimulationRequest,
        response_tx: oneshot::Sender<SimulationResponse>,
    ) -> SimResult<()> {
        let mut queue = self.queue.write().await;

        if queue.len() >= self.capacity {
            return Err(SimulationError::QueueFull {
                capacity: self.capacity,
                current: queue.len(),
            });
        }

        let queued = QueuedRequest {
            request,
            response_tx,
            enqueued_at: Instant::now(),
        };

        queue.push_back(queued);
        let new_len = queue.len();
        drop(queue);

        self.len.store(new_len, Ordering::SeqCst);

        // Notify waiting workers
        self.notify.notify_one();

        Ok(())
    }

    /// Dequeue a request
    ///
    /// # Returns
    /// * `SimResult<(SimulationRequest, oneshot::Sender<SimulationResponse>)>`
    ///
    /// # Blocking
    /// Waits for a request to become available.
    pub async fn dequeue(
        &self,
    ) -> SimResult<(SimulationRequest, oneshot::Sender<SimulationResponse>)> {
        loop {
            let mut queue = self.queue.write().await;

            if let Some(queued) = queue.pop_front() {
                let new_len = queue.len();
                drop(queue);

                self.len.store(new_len, Ordering::SeqCst);

                return Ok((queued.request, queued.response_tx));
            }

            drop(queue);

            // Wait for notification
            self.notify.notified().await;
        }
    }

    /// Get current queue length
    pub async fn len(&self) -> usize {
        self.len.load(Ordering::SeqCst)
    }

    /// Check if backpressure should be applied
    pub async fn is_backpressure(&self) -> bool {
        let current_len = self.len.load(Ordering::SeqCst);
        let utilization = current_len as f64 / self.capacity as f64;
        utilization >= self.backpressure_threshold
    }

    /// Get queue utilization percentage
    pub async fn utilization(&self) -> f64 {
        let current_len = self.len.load(Ordering::SeqCst);
        (current_len as f64 / self.capacity as f64) * 100.0
    }
}
```

---

## Deterministic RNG System

```rust
// ============================================================================
// MODULE: simulation_engine::rng
// PURPOSE: Deterministic random number generation
// ============================================================================

/// XorShift64* PRNG - Fast, deterministic, good quality
///
/// This RNG provides:
/// - Full 64-bit state space
/// - Period of 2^64 - 1
/// - Excellent statistical properties
/// - Fast generation (<5ns per number)
///
/// Thread Safety: Not thread-safe, use per-request instances
pub struct XorShift64Star {
    state: u64,
    operation_count: u32,
}

impl XorShift64Star {
    /// Create new RNG with given seed
    ///
    /// # Arguments
    /// * `seed` - Initial seed (must be non-zero)
    ///
    /// # Panics
    /// Panics if seed is 0
    pub fn new(seed: u64) -> Self {
        assert!(seed != 0, "XorShift64Star seed must be non-zero");

        Self {
            state: seed,
            operation_count: 0,
        }
    }

    /// Get operation count for metrics
    pub fn operations(&self) -> u32 {
        self.operation_count
    }
}

impl DeterministicRng for XorShift64Star {
    fn next_u64(&mut self) -> u64 {
        self.operation_count += 1;

        // XorShift64* algorithm
        let mut x = self.state;
        x ^= x >> 12;
        x ^= x << 25;
        x ^= x >> 27;
        self.state = x;

        x.wrapping_mul(0x2545F4914F6CDD1D)
    }

    fn next_f64(&mut self) -> f64 {
        // Generate 53 random bits and convert to [0, 1)
        let value = self.next_u64() >> 11;
        (value as f64) / ((1u64 << 53) as f64)
    }

    fn gen_range(&mut self, min: u64, max: u64) -> u64 {
        assert!(min < max, "Invalid range");

        let range = max - min;
        let value = self.next_u64();

        // Unbiased modulo reduction
        min + (value % range)
    }

    fn fill_bytes(&mut self, dest: &mut [u8]) {
        let mut chunks = dest.chunks_exact_mut(8);

        // Fill 8-byte chunks
        for chunk in &mut chunks {
            let value = self.next_u64();
            chunk.copy_from_slice(&value.to_le_bytes());
        }

        // Fill remainder
        let remainder = chunks.into_remainder();
        if !remainder.is_empty() {
            let value = self.next_u64();
            let bytes = value.to_le_bytes();
            remainder.copy_from_slice(&bytes[..remainder.len()]);
        }
    }

    fn get_state(&self) -> Vec<u8> {
        let mut state = Vec::with_capacity(12);
        state.extend_from_slice(&self.state.to_le_bytes());
        state.extend_from_slice(&self.operation_count.to_le_bytes());
        state
    }

    fn set_state(&mut self, state: &[u8]) -> SimResult<()> {
        if state.len() != 12 {
            return Err(SimulationError::InvalidRequest(
                "Invalid state length".to_string()
            ));
        }

        let mut state_bytes = [0u8; 8];
        state_bytes.copy_from_slice(&state[0..8]);
        self.state = u64::from_le_bytes(state_bytes);

        let mut count_bytes = [0u8; 4];
        count_bytes.copy_from_slice(&state[8..12]);
        self.operation_count = u32::from_le_bytes(count_bytes);

        Ok(())
    }

    fn fork(&mut self) -> Box<dyn DeterministicRng> {
        // Generate a seed for the child RNG
        let child_seed = self.next_u64();

        // Ensure non-zero seed
        let child_seed = if child_seed == 0 { 1 } else { child_seed };

        Box::new(XorShift64Star::new(child_seed))
    }
}

/// Thread-local RNG for non-deterministic mode
///
/// Uses OS randomness when determinism is not required.
pub struct ThreadRng {
    // Internal implementation would use getrandom or similar
    state: u64,
}

impl ThreadRng {
    pub fn new() -> Self {
        // In production, this would use getrandom() or /dev/urandom
        Self {
            state: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_nanos() as u64,
        }
    }
}

impl DeterministicRng for ThreadRng {
    fn next_u64(&mut self) -> u64 {
        // Fallback to XorShift for demo
        // Production would use getrandom
        let mut x = self.state;
        x ^= x >> 12;
        x ^= x << 25;
        x ^= x >> 27;
        self.state = x;
        x.wrapping_mul(0x2545F4914F6CDD1D)
    }

    fn next_f64(&mut self) -> f64 {
        let value = self.next_u64() >> 11;
        (value as f64) / ((1u64 << 53) as f64)
    }

    fn gen_range(&mut self, min: u64, max: u64) -> u64 {
        assert!(min < max, "Invalid range");
        let range = max - min;
        min + (self.next_u64() % range)
    }

    fn fill_bytes(&mut self, dest: &mut [u8]) {
        // Same implementation as XorShift64Star
        let mut chunks = dest.chunks_exact_mut(8);
        for chunk in &mut chunks {
            let value = self.next_u64();
            chunk.copy_from_slice(&value.to_le_bytes());
        }
        let remainder = chunks.into_remainder();
        if !remainder.is_empty() {
            let value = self.next_u64();
            let bytes = value.to_le_bytes();
            remainder.copy_from_slice(&bytes[..remainder.len()]);
        }
    }

    fn get_state(&self) -> Vec<u8> {
        self.state.to_le_bytes().to_vec()
    }

    fn set_state(&mut self, state: &[u8]) -> SimResult<()> {
        if state.len() != 8 {
            return Err(SimulationError::InvalidRequest(
                "Invalid state length".to_string()
            ));
        }
        let mut bytes = [0u8; 8];
        bytes.copy_from_slice(state);
        self.state = u64::from_le_bytes(bytes);
        Ok(())
    }

    fn fork(&mut self) -> Box<dyn DeterministicRng> {
        Box::new(ThreadRng::new())
    }
}

/// RNG utilities
pub mod rng_utils {
    use super::*;

    /// Sample from categorical distribution
    ///
    /// # Arguments
    /// * `rng` - Random number generator
    /// * `probabilities` - Probability weights (will be normalized)
    ///
    /// # Returns
    /// Index of sampled category
    pub fn sample_categorical(
        rng: &mut dyn DeterministicRng,
        probabilities: &[f64],
    ) -> usize {
        let total: f64 = probabilities.iter().sum();
        let mut sample = rng.next_f64() * total;

        for (i, &prob) in probabilities.iter().enumerate() {
            sample -= prob;
            if sample <= 0.0 {
                return i;
            }
        }

        probabilities.len() - 1
    }

    /// Sample from exponential distribution
    ///
    /// # Arguments
    /// * `rng` - Random number generator
    /// * `lambda` - Rate parameter
    ///
    /// # Returns
    /// Sampled value
    pub fn sample_exponential(rng: &mut dyn DeterministicRng, lambda: f64) -> f64 {
        -rng.next_f64().ln() / lambda
    }

    /// Sample from normal distribution (Box-Muller transform)
    ///
    /// # Arguments
    /// * `rng` - Random number generator
    /// * `mean` - Mean of distribution
    /// * `stddev` - Standard deviation
    ///
    /// # Returns
    /// Sampled value
    pub fn sample_normal(
        rng: &mut dyn DeterministicRng,
        mean: f64,
        stddev: f64,
    ) -> f64 {
        let u1 = rng.next_f64();
        let u2 = rng.next_f64();

        let z0 = (-2.0 * u1.ln()).sqrt() * (2.0 * std::f64::consts::PI * u2).cos();
        mean + stddev * z0
    }
}
```

---

## Session and State Management

```rust
// ============================================================================
// MODULE: simulation_engine::session
// PURPOSE: Session and conversation state management
// ============================================================================

use std::collections::HashMap;

/// Session state
///
/// Represents a user session with multiple conversations.
/// Thread-safe through RwLock protection.
#[derive(Debug)]
pub struct SessionState {
    /// Session identifier
    pub id: SessionId,

    /// Conversations in this session
    conversations: HashMap<ConversationId, Arc<RwLock<ConversationState>>>,

    /// Session metadata
    pub metadata: SessionMetadata,

    /// Session creation time
    pub created_at: Instant,

    /// Last access time
    pub last_accessed: Instant,
}

impl SessionState {
    pub fn new(id: SessionId) -> Self {
        let now = Instant::now();
        Self {
            id,
            conversations: HashMap::new(),
            metadata: SessionMetadata::default(),
            created_at: now,
            last_accessed: now,
        }
    }

    /// Get or create conversation
    pub fn get_or_create_conversation(
        &mut self,
        id: ConversationId,
    ) -> Arc<RwLock<ConversationState>> {
        self.last_accessed = Instant::now();

        self.conversations.entry(id)
            .or_insert_with(|| {
                Arc::new(RwLock::new(ConversationState::new(id)))
            })
            .clone()
    }

    /// Get conversation
    pub fn get_conversation(
        &self,
        id: ConversationId,
    ) -> Option<Arc<RwLock<ConversationState>>> {
        self.conversations.get(&id).cloned()
    }

    /// Remove conversation
    pub fn remove_conversation(&mut self, id: ConversationId) {
        self.conversations.remove(&id);
    }

    /// List all conversations
    pub fn list_conversations(&self) -> Vec<ConversationId> {
        self.conversations.keys().copied().collect()
    }

    /// Update last accessed time
    pub fn touch(&mut self) {
        self.last_accessed = Instant::now();
    }
}

/// Session metadata
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct SessionMetadata {
    /// User identifier
    pub user_id: Option<String>,

    /// Custom metadata
    pub custom: HashMap<String, serde_json::Value>,
}

/// Conversation state
///
/// Represents a single conversation thread with message history.
#[derive(Debug)]
pub struct ConversationState {
    /// Conversation identifier
    pub id: ConversationId,

    /// Message history
    history: VecDeque<Message>,

    /// Maximum history length
    max_history: usize,

    /// Conversation creation time
    pub created_at: Instant,

    /// Last message time
    pub last_message_at: Instant,

    /// Total messages
    pub total_messages: u64,
}

impl ConversationState {
    pub fn new(id: ConversationId) -> Self {
        let now = Instant::now();
        Self {
            id,
            history: VecDeque::new(),
            max_history: 100,
            created_at: now,
            last_message_at: now,
            total_messages: 0,
        }
    }

    /// Add message to history
    pub fn add_message(&mut self, message: Message) {
        self.history.push_back(message);
        self.total_messages += 1;
        self.last_message_at = Instant::now();

        // Trim history if needed
        while self.history.len() > self.max_history {
            self.history.pop_front();
        }
    }

    /// Get message history
    pub fn get_history(&self) -> Vec<Message> {
        self.history.iter().cloned().collect()
    }

    /// Get last N messages
    pub fn get_last_messages(&self, n: usize) -> Vec<Message> {
        self.history.iter()
            .rev()
            .take(n)
            .rev()
            .cloned()
            .collect()
    }

    /// Clear history
    pub fn clear_history(&mut self) {
        self.history.clear();
    }
}

/// Message in conversation history
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Message {
    /// Message role (user, assistant, system)
    pub role: String,

    /// Message content
    pub content: String,

    /// Message timestamp
    pub timestamp: Instant,

    /// Token count (if available)
    pub token_count: Option<u32>,
}

/// In-memory session store implementation
pub struct InMemorySessionStore {
    /// Session storage
    sessions: Arc<RwLock<HashMap<SessionId, Arc<RwLock<SessionState>>>>>,

    /// Session TTL
    ttl: Duration,

    /// Max conversation history
    max_history: usize,
}

impl InMemorySessionStore {
    pub fn new(ttl: Duration, max_history: usize) -> Self {
        Self {
            sessions: Arc::new(RwLock::new(HashMap::new())),
            ttl,
            max_history,
        }
    }
}

#[async_trait::async_trait]
impl SessionStore for InMemorySessionStore {
    async fn get_or_create_session(
        &self,
        session_id: &SessionId,
    ) -> SimResult<Arc<RwLock<SessionState>>> {
        let mut sessions = self.sessions.write().await;

        Ok(sessions.entry(session_id.clone())
            .or_insert_with(|| {
                Arc::new(RwLock::new(SessionState::new(session_id.clone())))
            })
            .clone())
    }

    async fn get_session(
        &self,
        session_id: &SessionId,
    ) -> SimResult<Arc<RwLock<SessionState>>> {
        let sessions = self.sessions.read().await;

        sessions.get(session_id)
            .cloned()
            .ok_or_else(|| SimulationError::SessionNotFound(session_id.clone()))
    }

    async fn remove_session(&self, session_id: &SessionId) -> SimResult<()> {
        let mut sessions = self.sessions.write().await;
        sessions.remove(session_id);
        Ok(())
    }

    async fn list_sessions(&self) -> SimResult<Vec<SessionId>> {
        let sessions = self.sessions.read().await;
        Ok(sessions.keys().cloned().collect())
    }

    async fn cleanup_expired(&self, ttl: Duration) -> SimResult<usize> {
        let mut sessions = self.sessions.write().await;
        let now = Instant::now();
        let mut removed = 0;

        sessions.retain(|_, session| {
            let session_guard = session.blocking_read();
            let age = now.duration_since(session_guard.last_accessed);
            let keep = age < ttl;

            if !keep {
                removed += 1;
            }

            keep
        });

        Ok(removed)
    }
}
```

---

## Queue and Backpressure

```rust
// ============================================================================
// MODULE: simulation_engine::backpressure
// PURPOSE: Backpressure detection and load shedding
// ============================================================================

/// Backpressure controller
///
/// Monitors queue depth and provides load shedding decisions.
pub struct BackpressureController {
    /// Queue reference
    queue: Arc<RequestQueue>,

    /// Metrics reference
    metrics: Arc<dyn MetricsCollector>,

    /// Backpressure threshold
    threshold: f64,

    /// Load shedding enabled
    load_shedding_enabled: bool,

    /// Load shedding probability when at capacity
    shed_probability: f64,
}

impl BackpressureController {
    pub fn new(
        queue: Arc<RequestQueue>,
        metrics: Arc<dyn MetricsCollector>,
        threshold: f64,
    ) -> Self {
        Self {
            queue,
            metrics,
            threshold,
            load_shedding_enabled: true,
            shed_probability: 0.5,
        }
    }

    /// Check if request should be accepted
    ///
    /// Returns true if request should be processed, false if shed.
    pub async fn should_accept_request(
        &self,
        request: &SimulationRequest,
    ) -> bool {
        if !self.load_shedding_enabled {
            return true;
        }

        // Check queue utilization
        let utilization = self.queue.utilization().await;

        if utilization < self.threshold * 100.0 {
            // Below threshold - accept all
            return true;
        }

        // Above threshold - probabilistic shedding
        // Priority affects shedding probability
        let priority_factor = (request.metadata.priority as f64) / 255.0;
        let adjusted_probability = self.shed_probability * (1.0 - priority_factor);

        let should_shed = rand::random::<f64>() < adjusted_probability;

        if should_shed {
            self.metrics.record_backpressure();
            tracing::warn!(
                request_id = %request.id.0,
                utilization = %utilization,
                "Request shed due to backpressure"
            );
        }

        !should_shed
    }

    /// Get current backpressure status
    pub async fn get_status(&self) -> BackpressureStatus {
        let utilization = self.queue.utilization().await;
        let is_backpressure = utilization >= self.threshold * 100.0;

        BackpressureStatus {
            utilization,
            is_backpressure,
            threshold: self.threshold * 100.0,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BackpressureStatus {
    pub utilization: f64,
    pub is_backpressure: bool,
    pub threshold: f64,
}
```

---

## Shutdown and Resource Cleanup

```rust
// ============================================================================
// MODULE: simulation_engine::shutdown
// PURPOSE: Graceful shutdown coordination
// ============================================================================

/// Shutdown coordinator
///
/// Manages graceful shutdown across all engine components.
pub struct ShutdownCoordinator {
    /// Shutdown signal
    signal: Arc<tokio::sync::Notify>,

    /// Shutdown complete signal
    complete: Arc<tokio::sync::Notify>,

    /// Active task counter
    active_tasks: Arc<AtomicUsize>,

    /// Shutdown timeout
    timeout: Duration,
}

impl ShutdownCoordinator {
    pub fn new(timeout: Duration) -> Self {
        Self {
            signal: Arc::new(tokio::sync::Notify::new()),
            complete: Arc::new(tokio::sync::Notify::new()),
            active_tasks: Arc::new(AtomicUsize::new(0)),
            timeout,
        }
    }

    /// Register a new task
    pub fn register_task(&self) {
        self.active_tasks.fetch_add(1, Ordering::SeqCst);
    }

    /// Unregister a task
    pub fn unregister_task(&self) {
        let prev = self.active_tasks.fetch_sub(1, Ordering::SeqCst);
        if prev == 1 {
            // Last task completed
            self.complete.notify_waiters();
        }
    }

    /// Initiate shutdown
    pub async fn initiate_shutdown(&self) -> SimResult<()> {
        tracing::info!("Initiating coordinated shutdown");

        // Signal all tasks to stop
        self.signal.notify_waiters();

        // Wait for tasks to complete (with timeout)
        let wait_result = tokio::time::timeout(
            self.timeout,
            self.wait_for_completion(),
        ).await;

        match wait_result {
            Ok(_) => {
                tracing::info!("All tasks completed gracefully");
                Ok(())
            }
            Err(_) => {
                let remaining = self.active_tasks.load(Ordering::SeqCst);
                tracing::warn!(
                    remaining_tasks = remaining,
                    "Shutdown timeout reached with tasks remaining"
                );
                Err(SimulationError::Internal(
                    format!("Shutdown timeout with {} tasks remaining", remaining)
                ))
            }
        }
    }

    /// Wait for all tasks to complete
    async fn wait_for_completion(&self) {
        while self.active_tasks.load(Ordering::SeqCst) > 0 {
            self.complete.notified().await;
        }
    }

    /// Check if shutdown has been signaled
    pub fn is_shutdown(&self) -> bool {
        // This is a simplified check - real implementation would use atomic flag
        self.active_tasks.load(Ordering::SeqCst) == 0
    }

    /// Get shutdown signal notifier
    pub fn signal(&self) -> Arc<tokio::sync::Notify> {
        Arc::clone(&self.signal)
    }
}

/// RAII guard for task registration
pub struct TaskGuard {
    coordinator: Arc<ShutdownCoordinator>,
}

impl TaskGuard {
    pub fn new(coordinator: Arc<ShutdownCoordinator>) -> Self {
        coordinator.register_task();
        Self { coordinator }
    }
}

impl Drop for TaskGuard {
    fn drop(&mut self) {
        self.coordinator.unregister_task();
    }
}
```

---

## Error Handling

```rust
// ============================================================================
// MODULE: simulation_engine::error_handling
// PURPOSE: Comprehensive error handling patterns
// ============================================================================

/// Error context for debugging
#[derive(Debug, Clone)]
pub struct ErrorContext {
    /// Request ID
    pub request_id: Option<RequestId>,

    /// Session ID
    pub session_id: Option<SessionId>,

    /// Timestamp
    pub timestamp: Instant,

    /// Stack of operations
    pub operation_stack: Vec<String>,

    /// Additional context
    pub context: HashMap<String, String>,
}

impl ErrorContext {
    pub fn new() -> Self {
        Self {
            request_id: None,
            session_id: None,
            timestamp: Instant::now(),
            operation_stack: Vec::new(),
            context: HashMap::new(),
        }
    }

    pub fn with_request(mut self, request_id: RequestId) -> Self {
        self.request_id = Some(request_id);
        self
    }

    pub fn with_session(mut self, session_id: SessionId) -> Self {
        self.session_id = Some(session_id);
        self
    }

    pub fn push_operation(mut self, operation: impl Into<String>) -> Self {
        self.operation_stack.push(operation.into());
        self
    }

    pub fn add_context(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.context.insert(key.into(), value.into());
        self
    }
}

/// Error with context
#[derive(Debug)]
pub struct ContextualError {
    pub error: SimulationError,
    pub context: ErrorContext,
}

impl ContextualError {
    pub fn new(error: SimulationError, context: ErrorContext) -> Self {
        Self { error, context }
    }
}

impl std::fmt::Display for ContextualError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.error)?;

        if let Some(req_id) = self.context.request_id {
            write!(f, " [request_id={}]", req_id.0)?;
        }

        if !self.context.operation_stack.is_empty() {
            write!(f, " [operations={:?}]", self.context.operation_stack)?;
        }

        Ok(())
    }
}

impl std::error::Error for ContextualError {}

/// Result type with context
pub type ContextResult<T> = Result<T, ContextualError>;

/// Error recovery strategies
pub enum RecoveryStrategy {
    /// Retry with exponential backoff
    Retry {
        max_attempts: u32,
        base_delay: Duration,
    },

    /// Fallback to alternative implementation
    Fallback,

    /// Fail fast - no recovery
    FailFast,

    /// Log and continue
    LogAndContinue,
}

/// Error handler
pub struct ErrorHandler {
    /// Metrics collector
    metrics: Arc<dyn MetricsCollector>,
}

impl ErrorHandler {
    pub fn new(metrics: Arc<dyn MetricsCollector>) -> Self {
        Self { metrics }
    }

    /// Handle error with recovery strategy
    pub async fn handle_error(
        &self,
        error: SimulationError,
        context: ErrorContext,
        strategy: RecoveryStrategy,
    ) -> SimResult<()> {
        // Log error
        tracing::error!(
            error = %error,
            request_id = ?context.request_id,
            session_id = ?context.session_id,
            operations = ?context.operation_stack,
            "Error occurred"
        );

        // Record metrics
        if let Some(req_id) = context.request_id {
            self.metrics.record_request_failed(req_id, &error);
        }

        // Execute recovery strategy
        match strategy {
            RecoveryStrategy::Retry { max_attempts, base_delay } => {
                // Retry logic would go here
                Err(error)
            }
            RecoveryStrategy::Fallback => {
                // Fallback logic would go here
                Err(error)
            }
            RecoveryStrategy::FailFast => {
                Err(error)
            }
            RecoveryStrategy::LogAndContinue => {
                Ok(())
            }
        }
    }
}
```

---

## Observability Integration

```rust
// ============================================================================
// MODULE: simulation_engine::observability
// PURPOSE: Metrics, tracing, and monitoring
// ============================================================================

use prometheus::{Counter, Gauge, Histogram, Registry};

/// Prometheus-based metrics collector
pub struct PrometheusMetricsCollector {
    /// Total requests
    requests_total: Counter,

    /// Successful requests
    requests_success: Counter,

    /// Failed requests
    requests_failed: Counter,

    /// Current queue depth
    queue_depth: Gauge,

    /// Active requests
    active_requests: Gauge,

    /// Processing time histogram
    processing_time: Histogram,

    /// Backpressure events
    backpressure_events: Counter,

    /// Registry
    registry: Registry,
}

impl PrometheusMetricsCollector {
    pub fn new() -> Self {
        let registry = Registry::new();

        let requests_total = Counter::new(
            "llm_simulator_requests_total",
            "Total number of requests",
        ).unwrap();

        let requests_success = Counter::new(
            "llm_simulator_requests_success_total",
            "Total number of successful requests",
        ).unwrap();

        let requests_failed = Counter::new(
            "llm_simulator_requests_failed_total",
            "Total number of failed requests",
        ).unwrap();

        let queue_depth = Gauge::new(
            "llm_simulator_queue_depth",
            "Current request queue depth",
        ).unwrap();

        let active_requests = Gauge::new(
            "llm_simulator_active_requests",
            "Current number of active requests",
        ).unwrap();

        let processing_time = Histogram::with_opts(
            prometheus::HistogramOpts::new(
                "llm_simulator_processing_time_seconds",
                "Request processing time in seconds",
            ).buckets(vec![
                0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0
            ])
        ).unwrap();

        let backpressure_events = Counter::new(
            "llm_simulator_backpressure_events_total",
            "Total number of backpressure events",
        ).unwrap();

        registry.register(Box::new(requests_total.clone())).unwrap();
        registry.register(Box::new(requests_success.clone())).unwrap();
        registry.register(Box::new(requests_failed.clone())).unwrap();
        registry.register(Box::new(queue_depth.clone())).unwrap();
        registry.register(Box::new(active_requests.clone())).unwrap();
        registry.register(Box::new(processing_time.clone())).unwrap();
        registry.register(Box::new(backpressure_events.clone())).unwrap();

        Self {
            requests_total,
            requests_success,
            requests_failed,
            queue_depth,
            active_requests,
            processing_time,
            backpressure_events,
            registry,
        }
    }

    /// Get Prometheus registry for export
    pub fn registry(&self) -> &Registry {
        &self.registry
    }
}

impl MetricsCollector for PrometheusMetricsCollector {
    fn record_request_received(&self, _request: &SimulationRequest) {
        self.requests_total.inc();
    }

    fn record_request_completed(&self, response: &SimulationResponse) {
        self.requests_success.inc();
        self.processing_time.observe(
            response.metrics.processing_time_ms / 1000.0
        );
    }

    fn record_request_failed(&self, _request_id: RequestId, _error: &SimulationError) {
        self.requests_failed.inc();
    }

    fn record_queue_depth(&self, depth: usize) {
        self.queue_depth.set(depth as f64);
    }

    fn record_active_requests(&self, count: usize) {
        self.active_requests.set(count as f64);
    }

    fn record_backpressure(&self) {
        self.backpressure_events.inc();
    }

    fn snapshot(&self) -> MetricsSnapshot {
        MetricsSnapshot {
            total_requests: self.requests_total.get() as u64,
            successful_requests: self.requests_success.get() as u64,
            failed_requests: self.requests_failed.get() as u64,
            current_queue_depth: self.queue_depth.get() as usize,
            active_requests: self.active_requests.get() as usize,
            avg_processing_time_ms: 0.0, // Would calculate from histogram
            p50_processing_time_ms: 0.0,
            p95_processing_time_ms: 0.0,
            p99_processing_time_ms: 0.0,
            backpressure_events: self.backpressure_events.get() as u64,
            timestamp: Instant::now(),
        }
    }
}

/// Distributed tracing integration
pub struct TracingIntegration {
    // Integration with OpenTelemetry or similar
}

impl TracingIntegration {
    pub fn new() -> Self {
        Self {}
    }

    /// Create span for request processing
    pub fn create_request_span(&self, request: &SimulationRequest) -> TraceSpan {
        TraceSpan {
            trace_id: format!("trace_{}", request.id.0),
            span_id: format!("span_{}", request.id.0),
            parent_span_id: None,
        }
    }
}

#[derive(Debug, Clone)]
pub struct TraceSpan {
    pub trace_id: String,
    pub span_id: String,
    pub parent_span_id: Option<String>,
}
```

---

## Usage Example

```rust
// ============================================================================
// EXAMPLE: Complete engine lifecycle
// ============================================================================

use simulation_engine::*;

#[tokio::main]
async fn main() -> SimResult<()> {
    // Initialize logging
    tracing_subscriber::fmt::init();

    // Create engine configuration
    let config = EngineConfig {
        max_concurrent_requests: 1000,
        queue_capacity: 10000,
        worker_threads: 8,
        global_seed: Some(42), // Deterministic mode
        session_ttl: Duration::from_secs(3600),
        max_conversation_history: 100,
        default_timeout: Duration::from_secs(30),
        enable_metrics: true,
        enable_tracing: true,
        backpressure_threshold: 0.8,
        shutdown_timeout: Duration::from_secs(30),
    };

    // Create engine
    let engine = Arc::new(SimulationEngine::new(config)?);

    // Register providers
    let openai_provider = Arc::new(OpenAIProvider::new());
    engine.register_provider(openai_provider).await?;

    let anthropic_provider = Arc::new(AnthropicProvider::new());
    engine.register_provider(anthropic_provider).await?;

    // Start engine
    engine.start().await?;

    // Create RAII guard for automatic shutdown
    let _guard = EngineGuard::new(Arc::clone(&engine));

    // Submit requests
    for i in 0..100 {
        let request = SimulationRequest {
            id: RequestId(i),
            session_id: SessionId(format!("session_{}", i % 10)),
            conversation_id: Some(ConversationId(i % 5)),
            provider: "openai".to_string(),
            model: "gpt-4".to_string(),
            payload: serde_json::json!({
                "messages": [
                    {"role": "user", "content": "Hello!"}
                ]
            }),
            metadata: RequestMetadata {
                correlation_id: Some(format!("req_{}", i)),
                priority: 128,
                timeout: Duration::from_secs(30),
                seed: Some(42 + i),
                tags: vec!["test".to_string()],
            },
            created_at: Instant::now(),
        };

        let response = engine.submit_request(request).await?;

        println!("Response: {:?}", response);
    }

    // Get metrics
    let metrics = engine.get_metrics();
    println!("Metrics: {:?}", metrics);

    // Graceful shutdown (or automatic via guard)
    engine.shutdown().await?;

    Ok(())
}
```

---

## Performance Characteristics

### Throughput
- **Target**: 10,000+ requests/second
- **Achieved via**:
  - Lock-free atomic operations where possible
  - Read-heavy optimizations (RwLock)
  - Pre-allocated buffers
  - Zero-copy message passing

### Latency
- **Target**: <5ms overhead
- **Breakdown**:
  - Queue enqueue: <100s
  - State lookup: <200s
  - RNG operations: <50ns per call
  - Metrics recording: <10s

### Memory
- **Session state**: ~1KB per session
- **Conversation state**: ~100 bytes + message history
- **Request queue**: O(queue_capacity)
- **Total overhead**: <100MB for 10,000 concurrent requests

### Determinism
- **XorShift64* RNG**: Full 64-bit state space
- **State checkpointing**: Full RNG state serialization
- **Reproducibility**: Exact reproduction with same seed
- **Verification**: Built-in state hash validation

---

## Thread Safety

### Read-Heavy Paths (RwLock)
- Provider registry (mostly reads after initialization)
- Session store (many concurrent reads)
- Configuration (read-only after creation)

### Write-Heavy Paths (Mutex or Atomic)
- Request queue (bounded with backpressure)
- Metrics counters (atomic increments)
- Request ID generation (atomic counter)

### Lock-Free Operations
- Active request counting (AtomicUsize)
- Queue length tracking (AtomicUsize)
- Shutdown signaling (atomic flags)

---

## Extension Points

1. **Custom Providers**: Implement `LLMProvider` trait
2. **Custom Metrics**: Implement `MetricsCollector` trait
3. **Custom Session Storage**: Implement `SessionStore` trait
4. **Custom RNG**: Implement `DeterministicRng` trait
5. **Middleware**: Hook into request processing pipeline

---

## Testing Considerations

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_deterministic_execution() {
        // Same seed produces same results
        let config1 = EngineConfig {
            global_seed: Some(42),
            ..Default::default()
        };

        let config2 = EngineConfig {
            global_seed: Some(42),
            ..Default::default()
        };

        // Process same request with both engines
        // Verify identical outputs
    }

    #[tokio::test]
    async fn test_backpressure() {
        // Fill queue to capacity
        // Verify QueueFull errors
        // Verify backpressure metrics
    }

    #[tokio::test]
    async fn test_graceful_shutdown() {
        // Submit long-running requests
        // Initiate shutdown
        // Verify requests complete
        // Verify clean resource cleanup
    }
}
```

---

## Production Checklist

- [ ] Comprehensive error handling
- [ ] Structured logging at all levels
- [ ] Prometheus metrics export
- [ ] OpenTelemetry tracing
- [ ] Health check endpoints
- [ ] Graceful degradation under load
- [ ] Resource leak prevention (RAII guards)
- [ ] Determinism verification tests
- [ ] Load testing (10K+ RPS)
- [ ] Chaos testing (failure injection)
- [ ] Memory profiling
- [ ] CPU profiling
- [ ] Documentation
- [ ] API stability guarantees

---

**End of Core Simulation Engine Design**
